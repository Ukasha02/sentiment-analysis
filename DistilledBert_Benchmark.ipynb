{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7629894,"sourceType":"datasetVersion","datasetId":4445485}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nfrom sklearn.metrics import accuracy_score\nimport time\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n\n# Function to encode reviews\ndef encode_reviews(tokenizer, reviews, max_length=128):  # Reduced max_length\n    return tokenizer(reviews, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n\n# Function to create a DataLoader\ndef create_data_loader(df, tokenizer, batch_size=16):\n    encodings = encode_reviews(tokenizer, df['review'].tolist(), max_length=128)  # Adjust max_length as needed\n    labels = torch.tensor(df['sentiment'].map({'positive': 1, 'negative': 0}).values)\n    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size)\n\n# Prediction function adjusted for DataLoader\ndef predict_sentiment(model, data_loader):\n    model.eval()\n    predictions, true_labels = [], []\n    with torch.no_grad():\n        for batch in tqdm(data_loader):\n            input_ids, attention_mask, labels = batch\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            predictions.extend(torch.argmax(logits, dim=-1).tolist())\n            true_labels.extend(labels.tolist())\n    return predictions, true_labels\n\n# Assuming test_df is your test dataset\ntest_df = pd.read_csv(\"/kaggle/input/progassign1/test.csv\")  # Load your test data\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:10:31.731849Z","iopub.execute_input":"2024-02-24T15:10:31.732247Z","iopub.status.idle":"2024-02-24T15:10:47.645104Z","shell.execute_reply.started":"2024-02-24T15:10:31.732217Z","shell.execute_reply":"2024-02-24T15:10:47.643523Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader for test dataset\ntest_data_loader = create_data_loader(test_df, tokenizer, batch_size=32)  # Adjust batch_size based on your RAM\n\nstart_time = time.time()\ntest_predictions, test_labels = predict_sentiment(model, test_data_loader)\nend_time = time.time()\n\n# Calculate accuracy\naccuracy = accuracy_score(test_labels, test_predictions)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Time taken: {end_time - start_time} seconds\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T15:10:47.647279Z","iopub.execute_input":"2024-02-24T15:10:47.647764Z","iopub.status.idle":"2024-02-24T15:45:59.025686Z","shell.execute_reply.started":"2024-02-24T15:10:47.647724Z","shell.execute_reply":"2024-02-24T15:45:59.024455Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"100%|██████████| 625/625 [34:58<00:00,  3.36s/it]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.83315\nTime taken: 2098.8907935619354 seconds\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}